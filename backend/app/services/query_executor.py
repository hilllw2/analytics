"""
Query Executor Service
Safely executes pandas code generated by LLM.
"""

import pandas as pd
import numpy as np
from typing import Dict, Any, Optional, Tuple, List
import traceback
from io import StringIO
import sys
from contextlib import redirect_stdout, redirect_stderr
import ast
from datetime import datetime, date

from app.core.session_manager import Session
from app.core.config import settings


def make_serializable(obj: Any) -> Any:
    """Convert any object to JSON-serializable format."""
    if obj is None:
        return None
    if isinstance(obj, (str, int, float, bool)):
        return obj
    if isinstance(obj, (datetime, date, pd.Timestamp)):
        return obj.isoformat() if pd.notna(obj) else None
    if isinstance(obj, (np.integer,)):
        return int(obj)
    if isinstance(obj, (np.floating,)):
        return float(obj) if not np.isnan(obj) else None
    if isinstance(obj, np.bool_):
        return bool(obj)
    if isinstance(obj, (np.ndarray,)):
        return [make_serializable(x) for x in obj.tolist()]
    if isinstance(obj, pd.Period):
        return str(obj)
    if pd.isna(obj):
        return None
    return str(obj)


def serialize_df_to_records(df: pd.DataFrame) -> List[dict]:
    """Convert DataFrame to list of dicts with proper serialization."""
    records = []
    for _, row in df.iterrows():
        record = {}
        for col in df.columns:
            record[str(col)] = make_serializable(row[col])
        records.append(record)
    return records


class SafeExecutor:
    """
    Safely executes pandas code with restricted globals.
    """
    
    # Allowed modules and functions
    SAFE_BUILTINS = {
        'abs', 'all', 'any', 'bool', 'dict', 'enumerate', 'filter',
        'float', 'format', 'frozenset', 'int', 'isinstance', 'len',
        'list', 'map', 'max', 'min', 'pow', 'print', 'range', 'reversed',
        'round', 'set', 'slice', 'sorted', 'str', 'sum', 'tuple', 'zip',
        'True', 'False', 'None'
    }
    
    # Dangerous patterns to block
    BLOCKED_PATTERNS = [
        'import os', 'import sys', 'import subprocess',
        '__import__', 'eval(', 'exec(', 'compile(',
        'open(', 'file(', 'input(',
        'globals(', 'locals(', 'vars(',
        '__builtins__', '__code__', '__class__',
        'system(', 'popen(', 'spawn',
    ]
    
    def __init__(self):
        pass
    
    def validate_code(self, code: str) -> Tuple[bool, Optional[str]]:
        """
        Validate code for safety before execution.
        
        Returns:
            Tuple of (is_safe, error_message)
        """
        code_lower = code.lower()
        
        # Check for blocked patterns
        for pattern in self.BLOCKED_PATTERNS:
            if pattern.lower() in code_lower:
                return False, f"Blocked pattern detected: {pattern}"
        
        # Try to parse as valid Python
        try:
            ast.parse(code)
        except SyntaxError as e:
            return False, f"Syntax error: {str(e)}"
        
        return True, None
    
    def create_safe_globals(self, df: pd.DataFrame, session: Session) -> Dict[str, Any]:
        """Create a restricted globals dict for code execution."""
        import scipy.stats as scipy_stats
        
        safe_globals = {
            # Core data tools
            'pd': pd,
            'np': np,
            'df': df.copy(),  # Work on a copy
            
            # Statistics
            'stats': scipy_stats,
            
            # Safe builtins
            '__builtins__': {
                name: getattr(__builtins__, name) if hasattr(__builtins__, name) 
                      else __builtins__[name] if isinstance(__builtins__, dict) else None
                for name in self.SAFE_BUILTINS
                if (hasattr(__builtins__, name) if not isinstance(__builtins__, dict) 
                    else name in __builtins__)
            },
            
            # Commonly needed
            'datetime': __import__('datetime'),
            'timedelta': __import__('datetime').timedelta,
            'date': __import__('datetime').date,
        }
        
        # Add pinned definitions as variables
        for name, defn in session.pinned_definitions.items():
            # These will be evaluated in context
            safe_globals[f'_def_{name}'] = defn.formula
        
        return safe_globals
    
    def execute(
        self,
        code: str,
        df: pd.DataFrame,
        session: Session,
        timeout_seconds: int = 30
    ) -> Dict[str, Any]:
        """
        Execute pandas code safely and return the result.
        
        Returns:
            Dict with 'success', 'result', 'result_type', 'stdout', 'error'
        """
        # Validate first
        is_safe, error_msg = self.validate_code(code)
        if not is_safe:
            return {
                "success": False,
                "result": None,
                "result_type": None,
                "stdout": "",
                "error": error_msg
            }
        
        # Prepare execution environment
        safe_globals = self.create_safe_globals(df, session)
        safe_locals = {}
        
        # Capture stdout
        stdout_capture = StringIO()
        stderr_capture = StringIO()
        
        try:
            with redirect_stdout(stdout_capture), redirect_stderr(stderr_capture):
                exec(code, safe_globals, safe_locals)
            
            # Look for result in various places
            result = None
            result_type = None
            
            if 'result' in safe_locals:
                result = safe_locals['result']
            elif 'output' in safe_locals:
                result = safe_locals['output']
            else:
                # Get the last assigned variable
                for var_name in reversed(list(safe_locals.keys())):
                    if not var_name.startswith('_'):
                        result = safe_locals[var_name]
                        break
            
            # Determine result type
            if result is not None:
                if isinstance(result, pd.DataFrame):
                    result_type = "dataframe"
                elif isinstance(result, pd.Series):
                    result_type = "series"
                elif isinstance(result, (int, float, np.integer, np.floating)):
                    result_type = "number"
                elif isinstance(result, str):
                    result_type = "string"
                elif isinstance(result, (list, tuple)):
                    result_type = "list"
                elif isinstance(result, dict):
                    result_type = "dict"
                else:
                    result_type = "other"
            
            return {
                "success": True,
                "result": result,
                "result_type": result_type,
                "stdout": stdout_capture.getvalue(),
                "error": None
            }
            
        except Exception as e:
            return {
                "success": False,
                "result": None,
                "result_type": None,
                "stdout": stdout_capture.getvalue(),
                "error": f"{type(e).__name__}: {str(e)}\n{traceback.format_exc()}"
            }


class QueryExecutor:
    """
    High-level query execution service.
    """
    
    def __init__(self):
        self.safe_executor = SafeExecutor()
    
    async def execute_query(
        self,
        code: str,
        session: Session,
        max_result_rows: int = 1000
    ) -> Dict[str, Any]:
        """
        Execute a query and format the result.
        
        Returns formatted result suitable for API response.
        """
        if not session.active_dataset:
            return {
                "success": False,
                "error": "No active dataset. Please upload a file first.",
                "result": None
            }
        
        df = session.active_df
        
        # Execute code
        exec_result = self.safe_executor.execute(code, df, session)
        
        if not exec_result["success"]:
            return {
                "success": False,
                "error": exec_result["error"],
                "result": None,
                "raw_result": None
            }
        
        # Format result
        result = exec_result["result"]
        formatted = self._format_result(result, max_result_rows)
        
        return {
            "success": True,
            "error": None,
            "result": formatted["data"],
            "raw_result": result,  # Keep the raw DataFrame/result for charting
            "result_type": exec_result["result_type"],
            "display_type": formatted["display_type"],
            "row_count": formatted.get("row_count"),
            "truncated": formatted.get("truncated", False),
            "stdout": exec_result["stdout"]
        }
    
    def _format_result(
        self,
        result: Any,
        max_rows: int
    ) -> Dict[str, Any]:
        """Format execution result for display."""
        
        if result is None:
            return {
                "data": None,
                "display_type": "none"
            }
        
        if isinstance(result, pd.DataFrame):
            truncated = len(result) > max_rows
            df_display = result.head(max_rows)
            
            return {
                "data": {
                    "columns": [str(c) for c in df_display.columns],
                    "data": serialize_df_to_records(df_display),
                    "dtypes": {str(col): str(dtype) for col, dtype in df_display.dtypes.items()}
                },
                "display_type": "table",
                "row_count": len(result),
                "truncated": truncated
            }
        
        if isinstance(result, pd.Series):
            truncated = len(result) > max_rows
            series_display = result.head(max_rows)
            
            return {
                "data": {
                    "name": str(result.name) if result.name else "value",
                    "index": [make_serializable(x) for x in series_display.index],
                    "values": [make_serializable(x) for x in series_display.tolist()],
                    "dtype": str(result.dtype)
                },
                "display_type": "series",
                "row_count": len(result),
                "truncated": truncated
            }
        
        if isinstance(result, (int, float, np.integer, np.floating)):
            return {
                "data": float(result) if not np.isnan(result) else None,
                "display_type": "number"
            }
        
        if isinstance(result, str):
            return {
                "data": result,
                "display_type": "text"
            }
        
        if isinstance(result, dict):
            return {
                "data": self._serialize_dict(result),
                "display_type": "dict"
            }
        
        if isinstance(result, (list, tuple)):
            return {
                "data": [make_serializable(x) for x in list(result)[:max_rows]],
                "display_type": "list",
                "truncated": len(result) > max_rows
            }
        
        # Fallback: convert to string
        return {
            "data": make_serializable(result),
            "display_type": "text"
        }
    
    def _serialize_dict(self, d: dict) -> dict:
        """Recursively serialize dict for JSON."""
        result = {}
        for k, v in d.items():
            key = str(k)
            if isinstance(v, pd.DataFrame):
                result[key] = serialize_df_to_records(v)
            elif isinstance(v, pd.Series):
                result[key] = [make_serializable(x) for x in v.tolist()]
            elif isinstance(v, dict):
                result[key] = self._serialize_dict(v)
            elif isinstance(v, (list, tuple)):
                result[key] = [make_serializable(x) for x in v]
            else:
                result[key] = make_serializable(v)
        return result
    
    async def execute_filter(
        self,
        session: Session,
        filter_expr: str
    ) -> Dict[str, Any]:
        """Apply a filter to the active dataset."""
        code = f"result = df.query('{filter_expr}')"
        return await self.execute_query(code, session)
    
    async def execute_aggregation(
        self,
        session: Session,
        group_by: list,
        agg_column: str,
        agg_func: str
    ) -> Dict[str, Any]:
        """Execute a groupby aggregation."""
        group_cols = ", ".join([f"'{c}'" for c in group_by])
        code = f"result = df.groupby([{group_cols}])['{agg_column}'].{agg_func}().reset_index()"
        return await self.execute_query(code, session)
    
    async def execute_sort(
        self,
        session: Session,
        sort_column: str,
        ascending: bool = True,
        top_n: Optional[int] = None
    ) -> Dict[str, Any]:
        """Sort and optionally limit results."""
        code = f"result = df.sort_values('{sort_column}', ascending={ascending})"
        if top_n:
            code += f".head({top_n})"
        return await self.execute_query(code, session)


# Singleton instance
query_executor = QueryExecutor()
